{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surrogate Evaluation Notebook\n",
    "\n",
    "This notebook documents the prototype workflow for training and evaluating\n",
    "surrogate models against curated waveform datasets. It is designed to run\n",
    "deterministically by fixing random seeds and reusing manifests generated via\n",
    "`tools/datasets/curate_waveforms.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "reproducibility"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from igsoa_analysis.surrogates.pytorch_surrogate import FeedForwardSurrogate\n",
    "\n",
    "# Training configuration is version controlled to guarantee reproducibility.\n",
    "TRAINING_CONFIG = {\n",
    "    \"seed\": 42,\n",
    "    \"input_dim\": 128,\n",
    "    \"output_dim\": 64,\n",
    "    \"hidden_layers\": [256, 256],\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 25,\n",
    "}\n",
    "\n",
    "torch.manual_seed(TRAINING_CONFIG[\"seed\"])\n",
    "np.random.seed(TRAINING_CONFIG[\"seed\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "data-loading"
    ]
   },
   "outputs": [],
   "source": [
    "DATASET_ROOT = Path(\"analysis/datasets\")\n",
    "DATASET_NAME = \"example_waveforms\"\n",
    "MANIFEST_PATH = DATASET_ROOT / DATASET_NAME / \"manifest.json\"\n",
    "\n",
    "if not MANIFEST_PATH.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Manifest {MANIFEST_PATH} not found. Run the curation script to generate it.\"\n",
    "    )\n",
    "\n",
    "manifest = json.loads(MANIFEST_PATH.read_text(encoding=\"utf-8\"))\n",
    "print(f'Loaded {manifest[\"sample_count\"]} samples for training/evaluation.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "training"
    ]
   },
   "outputs": [],
   "source": [
    "model = FeedForwardSurrogate.from_config(TRAINING_CONFIG)\n",
    "print(model)\n",
    "\n",
    "# Placeholder training loop: replace with DataLoader built from manifest entries.\n",
    "dummy_inputs = torch.randn(128, TRAINING_CONFIG[\"input_dim\"])\n",
    "dummy_targets = torch.randn(128, TRAINING_CONFIG[\"output_dim\"])\n",
    "loss_history = model.train_on_arrays(dummy_inputs, dummy_targets, epochs=2)\n",
    "print('Recorded loss trajectory:', loss_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "evaluation"
    ]
   },
   "outputs": [],
   "source": [
    "# Evaluate surrogate predictions for latency/accuracy benchmarking.\n",
    "with torch.no_grad():\n",
    "    predictions = model(dummy_inputs[:16])\n",
    "    mse = torch.mean((predictions - dummy_targets[:16]) ** 2).item()\n",
    "    print(f'MSE on hold-out batch: {mse:.6f}')\n",
    "\n",
    "benchmark_record = {\n",
    "    \"dataset\": DATASET_NAME,\n",
    "    \"config\": TRAINING_CONFIG,\n",
    "    \"metric\": \"mse\",\n",
    "    \"value\": mse,\n",
    "}\n",
    "print(json.dumps(benchmark_record, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
