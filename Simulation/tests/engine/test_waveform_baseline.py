"""Baseline verification tests for IGSOA engine artifacts."""
from __future__ import annotations

import csv
import json
from pathlib import Path

ROOT = Path(__file__).resolve().parents[2]
VERIFICATION_FILE = ROOT / "verification_results_20251023_054706.json"
WAVEFORM_FILE = ROOT / "gw_waveform_alpha_1.500000.csv"


def load_verification() -> dict:
    """Load verification JSON generated by the legacy test harness."""
    if not VERIFICATION_FILE.exists():
        raise FileNotFoundError(f"Missing verification dataset: {VERIFICATION_FILE}")
    return json.loads(VERIFICATION_FILE.read_text())


def test_oscillator_frequencies_within_tolerance():
    """Ensure the synthetic oscillator sweeps hit the analytic frequencies."""
    data = load_verification()["tests"]
    expected = {
        "oscillator_100.0hz": 100.0,
        "oscillator_440.0hz": 440.0,
        "oscillator_1000.0hz": 1000.0,
    }
    tolerance_hz = 1e-6

    for test_name, target in expected.items():
        result = data[test_name]
        measured = float(result["frequency_hz"])
        assert abs(measured - target) <= tolerance_hz, (
            f"{test_name}: measured {measured} Hz, expected {target} Hz"
        )


def test_filter_energy_ratios_match_benchmark():
    """Match the analytic 9/34 energy attenuation ratio across window sizes."""
    data = load_verification()["tests"]
    expected_ratio = 9 / 34  # 0.2647058823529412
    tolerance = 5e-8

    for samples in (64, 128, 256, 512, 1024):
        key = f"filter_{samples}samples"
        ratio = float(data[key]["energy_ratio"])
        assert abs(ratio - expected_ratio) <= tolerance, (
            f"{key}: ratio {ratio} diverges from analytic benchmark {expected_ratio}"
        )


def test_engine_performance_targets():
    """The AVX2 engine should hit the documented latency and speedup goals."""
    perf = load_verification()["tests"]["engine_integration"]

    assert perf["target_achieved"], "Performance target flag dropped to False"
    assert float(perf["ns_per_op"]) <= 100.0, "Nanoseconds per operation regressed"
    assert float(perf["speedup"]) >= 150.0, "Speedup fell below analytic baseline"


def test_waveform_alpha_scaling_curve():
    """Validate the gravitational waveform amplitude scaling for alpha=1.5."""
    if not WAVEFORM_FILE.exists():
        raise FileNotFoundError(f"Missing waveform dataset: {WAVEFORM_FILE}")

    with WAVEFORM_FILE.open(newline="") as handle:
        reader = csv.DictReader(handle)
        amplitudes = [float(row["amplitude"]) for row in reader]

    assert amplitudes, "No samples were loaded from the waveform CSV"

    peak_amplitude = max(amplitudes)
    alpha = 1.5
    analytic_base = 1.951502133e-19  # Derived from quadrupole scaling law for alpha = 1
    expected_peak = analytic_base * alpha ** 2
    tolerance = expected_peak * 0.02  # 2% band preserves physics significance

    assert abs(peak_amplitude - expected_peak) <= tolerance, (
        "Waveform peak amplitude deviates from analytic expectation: "
        f"observed {peak_amplitude:.3e}, expected {expected_peak:.3e}"
    )
